{"version":3,"file":"bundle.3199.js","mappings":";;;;;;AAAa;AACb,QAAQ,YAAY,EAAE,mBAAO,CAAC,KAAc;AAC5C,oBAAoB,iDAAyC;;AAE7D;AACA;AACA,eAAe,QAAQ;AACvB,eAAe,WAAW;AAC1B;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA,eAAe,QAAQ;AACvB,iBAAiB;AACjB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA,iBAAiB;AACjB;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,WAAW,QAAQ;AACnB,WAAW,iDAAiD;AAC5D,aAAa,iDAAiD;AAC9D;AACA;AACA;AACA;AACA;AACA,4BAA4B,mCAAmC;AAC/D;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;;AAEA;AACA;AACA","sources":["webpack://ace-playground/./node_modules/ace-code/src/ext/simple_tokenizer.js"],"sourcesContent":["\"use strict\";\nconst { Tokenizer } = require(\"../tokenizer\");\nconst isTextToken = require(\"../layer/text_util\").isTextToken;\n\nclass SimpleTokenizer {\n    /**\n     * @param {string} content \n     * @param {Tokenizer} tokenizer \n     */\n    constructor(content, tokenizer) {\n        this._lines = content.split(/\\r\\n|\\r|\\n/);\n        this._states = [];\n        this._tokenizer = tokenizer;\n    }   \n\n    /**\n     * @param {number} row \n     * @returns {import(\"../../ace-internal\").Ace.Token[]}\n     */\n    getTokens(row) {\n        const line = this._lines[row];\n        const previousState = this._states[row - 1];\n        \n        const data = this._tokenizer.getLineTokens(line, previousState);\n        this._states[row] = data.state;\n        return data.tokens;\n    }\n\n    /**\n     * @returns {number} \n     */\n    getLength() {\n        return this._lines.length;\n    }\n}\n\n/**\n * Parses provided content according to provided highlighting rules and return tokens. \n * Tokens either have the className set according to Ace themes or have no className if they are just pure text tokens.\n * Result is a list of list of tokens, where each line from the provided content is a separate list of tokens.\n * \n * @param {string} content to tokenize \n * @param {import(\"../../ace-internal\").Ace.HighlightRules} highlightRules defining the language grammar \n * @returns {import(\"../../ace-internal\").Ace.TokenizeResult} tokenization result containing a list of token for each of the lines from content\n */\nfunction tokenize(content, highlightRules) {\n    const tokenizer = new SimpleTokenizer(content, new Tokenizer(highlightRules.getRules()));\n    \n    let result = [];\n    for (let lineIndex = 0; lineIndex < tokenizer.getLength(); lineIndex++) {\n        const lineTokens = tokenizer.getTokens(lineIndex);\n        result.push(lineTokens.map((token) => ({\n            className: isTextToken(token.type) ? undefined : \"ace_\" + token.type.replace(/\\./g, \" ace_\"),\n            value: token.value\n        })));\n    }\n    return result;\n}\n\nmodule.exports = {\n    tokenize\n};\n"],"names":[],"sourceRoot":""}